# IMP 间接预取

主要解决的模式是 ```A[B[i]]``` 这样的访问模式，主要是观察到了 ```B[i]``` 往往是提前计算好并放在 memory 中。同时这部分的 ```B[i]``` 往往局部性不错，可以被其他预取到，这篇文章的方法想将这个结合起来，在预取 ```B[i]``` 的时候也驱动 ```A[B[i]]``` 的预取。

同时这篇文章发现这种间接访问的模式很少具有空间的局部性，因此在尝试预取A数组中的数据时候，预取的粒度可以更小。

## 动机

```B[i]``` 往往比较固定，同时 A 的数组会很大，又由于上面提到的局部性差的原因，这部分往往造成很大的 L1 cache miss。

## 架构

基于以下设计，如果访问 ```B[i]``` 很早，且我们学习到了 BaseAddr 和 element 的大小，我们就能发起预取。

因为 A 数组中的元素大小可能很多，为了避免设计的复杂，只考虑是 2 的倍数的，因此可以用位移来代替乘法。默认的 shift 在设计的时候已经固定，因此只能识别到在这个 shift 内的。

## 架构优化

1. 针对 PT 的优化。
2. 针对多级追逐的优化。


## 可以用于虚拟地址和物理地址的预取

用虚拟地址可以识别更长的 stream 用，物理地址的预取不能跨页。物理地址更快，但是受到限制。

虚拟地址预取的好处是提前发起 TLB/pagetable walk，这样等 load 执行的时候，很可能 TLB 是 hit 的，等这部分地址翻译的时间做完了，很可能这条 load 被真实的执行了，因此及时性可以被保证。物理地址的预取省去了地址翻译的过程，因此可能会很快的进入到 l1，可能会不及时，这个感觉得具体情况具体分析。但是虚拟地址预取的准确性也很重要，如果给的地址不对，实际上可能会发生 3 - 4 次的 pagetable work。
